# -*- coding: utf-8 -*-
"""SYNTECXHUB_Correlation heatmap & pairwise relationships

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UcitAEBVB9HNBD0gF15Y_3WaP95sKOh8
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("/content/data (1).csv")

# Convert date column
df['date'] = pd.to_datetime(df['date'])

# Select numeric features only
numeric_df = df.select_dtypes(include=[np.number])

# Handle missing values
numeric_df = numeric_df.fillna(numeric_df.median())

corr_matrix = numeric_df.corr(method="pearson")

from ipywidgets import interact

def heatmap_threshold(min_corr=0.3):
    sns.heatmap(corr_matrix.where(abs(corr_matrix)>=min_corr), cmap='coolwarm', annot=True, fmt=".2f")
interact(heatmap_threshold, min_corr=(0.1, 1.0, 0.05))

# =========================================================
# 7. pairplot for the top-6 correlated pairs
# =========================================================
# pick the 6 highest absolute correlations
top_pairs = corr_pairs.head(6).index
top_features = list(set([t for pair in top_pairs for t in pair]))

sns.pairplot(numeric_df[top_features], corner=True, diag_kind="kde", plot_kws={"alpha": 0.6})
plt.suptitle("Pairwise relationships â€“ highest |Ï|", y=0.99)
plt.show()

# =========================================================
# 6. strongest relationships
# =========================================================
# flatten the matrix and remove self-correlations
corr_pairs = (
    corr_matrix.where(np.tril(np.ones(corr_matrix.shape), k=-1).astype(bool))
    .stack()
    .sort_values(key=abs, ascending=False)
)

print("ðŸ”¥  Strongest POSITIVE correlations")
print(corr_pairs[corr_pairs > 0].head(10))
print("\nðŸ§Š  Strongest NEGATIVE correlations")
print(corr_pairs[corr_pairs < 0].head(10))

sns.lmplot(
    data=df.assign(decade=(df.yr_built//10)*10),
    x='sqft_living', y='price', hue='decade',
    height=5, aspect=1.4, scatter_kws={'alpha':0.4}
)
plt.xscale('log')
plt.yscale('log')
plt.title("Price vs. Living Area â€“ same slope, higher intercept for newer decade")

def top_corr(df):
    c = df.corr().abs().unstack().sort_values(ascending=False)
    return c[c.between(0.05, 0.99)].head(10)  # drop self-corr

c1 = top_corr(numeric_df.sample(frac=0.5, random_state=1))
c2 = top_corr(numeric_df.sample(frac=0.5, random_state=2))
pd.concat([c1, c2], axis=1, keys=['Split-A', 'Split-B']).plot(kind='bar', figsize=(6,3))

hi = df['sqft_living'].quantile(0.75)
lo = df['sqft_living'].quantile(0.25)
delta = (df[df['sqft_living']>=hi]['price'].median() -
         df[df['sqft_living']<=lo]['price'].median())
print(f"Extra 1 000 sqft â‰ˆ ${delta/1000:.0f}k premium")

